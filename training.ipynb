{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae5505",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_DIR = \"data/train/images\"\n",
    "TRAIN_LABEL_DIR = \"data/train/labels\"\n",
    "VAL_IMG_DIR = \"data/val/images\"\n",
    "VAL_LABEL_DIR = \"data/val/labels\"\n",
    "\n",
    "NUM_KEYPOINTS = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all the images has the same resolution\n",
    "import os\n",
    "from PIL import Image\n",
    "def check_images_resolution(folder_path):\n",
    "    resolutions = set()\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            with Image.open(image_path) as img:\n",
    "                resolutions.add(img.size)\n",
    "    return len(resolutions) == 1, resolutions.pop() if resolutions else None\n",
    "\n",
    "check_images_resolution('data/train/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89098af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all the labels has the same number of keypoints\n",
    "def check_labels_keypoints(folder_path):\n",
    "    keypoints_counts = set()\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            label_path = os.path.join(folder_path, filename)\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                keypoints_counts.add(len(lines))\n",
    "    return len(keypoints_counts) == 1, keypoints_counts.pop() if keypoints_counts else None\n",
    "\n",
    "check_labels_keypoints('data/train/labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daffd6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the labels with the wrong number of keypoints\n",
    "def remove_wrong_labels(folder_path, expected_keypoints):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            label_path = os.path.join(folder_path, filename)\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                if len(lines) != expected_keypoints:\n",
    "                    os.remove(label_path)\n",
    "                    print(f\"Removed {label_path} with {len(lines)} keypoints\")\n",
    "\n",
    "remove_wrong_labels('data/train/labels', expected_keypoints=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91175797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove from data/train/images those images that don't have a corresponding .txt file in data/train/labels\n",
    "import os\n",
    "\n",
    "def remove_unlabelled_images(image_dir, label_dir):\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    label_files = [f for f in os.listdir(label_dir) if f.lower().endswith('.txt')]\n",
    "    \n",
    "    label_basenames = set(os.path.splitext(f)[0] for f in label_files)\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_basename = os.path.splitext(image_file)[0]\n",
    "        if image_basename not in label_basenames:\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            print(f\"Removing unlabelled image: {image_path}\")\n",
    "            os.remove(image_path)\n",
    "\n",
    "remove_unlabelled_images('data/train/images', 'data/train/labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3756517",
   "metadata": {},
   "source": [
    "# Training pipeline for the ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c91495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNet18, KeypointDataset, train_model\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8adde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True\n",
    "NUM_EPOCHS = 100\n",
    "SAVE_INTERVAL = 5\n",
    "PATIENCE = 0\n",
    "\n",
    "TRAIN_LOSS_PATH = \"train_loss.npy\"\n",
    "VAL_LOSS_PATH = \"val_loss.npy\"\n",
    "LOSS_PLOT_PATH = \"loss_plot.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eaf770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = ResNet18(num_keypoints=NUM_KEYPOINTS, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2612ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    # TODO: For now, remove geometric transforms (they are only applied to images). We'll use Albumenations to also change labels\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)), # Random rotation and translation\n",
    "    transforms.Resize((1920, 1080)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Keep validation transforms simple (no augmentation) to evaluate true performance\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((1920, 1080)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cffbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "\n",
    "train_dataset = KeypointDataset(TRAIN_IMG_DIR, TRAIN_LABEL_DIR, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "val_dataset = KeypointDataset(VAL_IMG_DIR, VAL_LABEL_DIR, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f407c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "train_loss, val_loss = train_model(model, train_loader, val_loader, num_epochs=NUM_EPOCHS, save_interval=SAVE_INTERVAL, patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb364f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lists of losses, accuracy and dice scores\n",
    "\n",
    "import numpy as np\n",
    "np.save(TRAIN_LOSS_PATH, np.array(train_loss))\n",
    "np.save(VAL_LOSS_PATH, np.array(val_loss))\n",
    "\n",
    "# To load the saved lists, use:\n",
    "# train_loss = np.load(\"train_loss.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcec8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure()\n",
    "plt.title(\"Training and validation losses over epochs\")\n",
    "plt.plot(train_loss, label=\"Train loss\")\n",
    "plt.plot(val_loss, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(LOSS_PLOT_PATH)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kpdetector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
